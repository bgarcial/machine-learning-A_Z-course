{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../data/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cualquier dataset necesitamos hacer una distinción entre las variables independientes y las dependientes\n",
    "\n",
    "En el dataset anterior,  las variables independientes son  `Country`, `Age` y `Salary`.\n",
    "La variable/columna `Purchased`  es una variable dependiente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, a partir del dataset anterior, creamos una matriz solo para referenciar las variables independientes: `Country`, `Age` y `Salary`, por lo que tomamos todas las columnas menos la de `Purchased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Es asi como la matriz de variables independientes `X` queda de esta forma:\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambien a partir del conjunto de datos original representado por la variable `dataset` creamos un vector solo \n",
    "para la variable independiente `Purchased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removiendo datos faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy común tener un conjunto de datos, en donde en algunas celdas o líneas o registros, existan datos faltantes \n",
    "tipo `NaN` como es el caso de nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Age'][6])\n",
    "print(dataset['Salary'][4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Que hacemos con estos valores faltantes? ** \n",
    "\n",
    "La primera idea es remover las líneas de las muestras o registros en donde hay datos faltantes, pero dependiendo del contexto esto puede ser peligroso porque puede contener información crucial. Es mejor pensar en otra idea.\n",
    "\n",
    "Una alternativa de solucion mas comun es tomar la media de los valores de las columna en donde faltan los datos, en este caso `Age` y `Salary`\n",
    "\n",
    "Para el caso de la columna `Age`\n",
    "\n",
    "![alt text](https://cldup.com/WSQFnqNeuX-3000x3000.png \"Llenando el espacio faltante con la media de los demas valores\")\n",
    "\n",
    "Para el caso de la columna `Salary`\n",
    "\n",
    "![alt text](https://cldup.com/ThRBQavgo4-2000x2000.png \"Llenando el espacio faltante con la media de los demas valores\")\n",
    "\n",
    "\n",
    "Otras estrategias son tomar la mediana de los valores restantes de la columna en donde falta un valor, O tomar el valor más frecuente, lo cual puede ser una buena idea dependiendo del contexto\n",
    "\n",
    "Tomaremos la media de las columnas, reemplazaremos los datos que faltan aqui por la media de todos los valores en la columna `Age` de el dataset original\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando `scikit-learn` a través de la clase [Imputer](# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html\n",
    " \"sklearn.preprocessing.Imputer\"), que es una de las diferentes clases para preprocesamiento de datos se llenaran los datos faltantes del dataset:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Age'][6])\n",
    "print(dataset['Salary'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase [Imputer](# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html\n",
    " \"sklearn.preprocessing.Imputer\") tiene los siguientes parámetros:\n",
    " \n",
    " ![alt text](https://cldup.com/NkWAcChKsj-3000x3000.png \"Imputer parameters\")\n",
    " \n",
    " Utilizaremos como estrategia, llenar los datos faltantes con la media de los otros valores de la columna \n",
    " en donde faltan datos.\n",
    " \n",
    " `axis` es el eje a lo largo del cual vamos a hacer la operación de `impute`, por defecto es igual a 0, lo que significa\n",
    " que dicha operación será a lo largo de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijamos los valores transformando las columnas en donde hace falta datos con el metodo `fit()` le pasamos la matriz `X` formada a partir del dataset original dataset y el cual solo tiene las variables independientes de `Age` y `Salary` en donde se encuentras los valores vacios \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Averiguamos cuales son los índices de las columnas con esta función\n",
    "desarrollada aqui: https://stackoverflow.com/a/38489403/2773461\n",
    "la cual usa el metodo searchsorted de numpy\n",
    "\"\"\"\n",
    "def column_index(df, query_cols):\n",
    "    cols = df.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols,query_cols,sorter=sidx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_index(dataset, ['Country', 'Age', 'Salary', 'Purchased'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Country' 'Age' 'Salary' 'Purchased']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns.get_values()[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como los valores faltantes estan en `Age` y `Salary` debemos capturar solo las columnas 1 y 2 que son las que corresponden a `Age` y `Salary`\n",
    "\n",
    "Con slices, (`:`) le decimos `X[:, 1:3]` \n",
    "\n",
    "Capture todas las lineas de la matriz `X`  con los primeros `:` \n",
    "Tenemos que seleccionar las columnas 1 y 2 por ello con la instrucción `1:3` las abarcamos, ya que \n",
    "en python cuando se trabaja con slices, el límite superior es excluido.\n",
    "\n",
    "Al poner 3 nos da la columna 2 que es `Salary` que es en donde hay otro dato faltante y de esta manera estamos\n",
    "tomando los indices 0,1 y 2 con imputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que imputer lo tenemos asi:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijamos los valores de las columnas en donde hacen falta datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = imputer.fit(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora reemplazamos los datos faltantes en la matriz X descritos antes, por la media de los demas valores de dichas columnas en donde faltan datos\n",
    "\n",
    "Seleccionamos las columnas en donde faltan datos, tomamos todas los valores (`:`) de las columnas cuyos indices son `1` y `2` y usamos el metodo `transform()` el cual reemplazara los datos faltantes por la media de la columna y le pasamos las columnas sobre las cuales actuar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora vemos que los valores faltantes que habían en nuestro dataset original\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [40.0 63777.77777777778]\n",
      " [35.0 58000.0]\n",
      " [38.77777777777778 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# Han sido completados con el promedio de los valores de la columna a la cual pertenecen \n",
    "print(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los valores nulos en el dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Age'][6])\n",
    "print(dataset['Salary'][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los valores ya completados en la matriz X conformada y afectada por la clase Imputer de scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.77777777777778\n"
     ]
    }
   ],
   "source": [
    "print(X[:, 1][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63777.77777777778\n"
     ]
    }
   ],
   "source": [
    "print(X[:, 2][4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas tambien tiene un metodo para llenar valores faltantes el cual es `fillna()` el cual tiene argumentos como el de `value`, para establecerle el valor que queremos poner en reemplazo de un dato faltante\n",
    "\n",
    "El método [fillna](# https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.fillna.html\n",
    " \"pandas.DataFrame.fillna\") tiene los siguientes parámetros:\n",
    " \n",
    " ![alt text](https://cldup.com/HAIXiyfYIT-3000x3000.png \"fillna parameters\")\n",
    "\n",
    "Le decimos que llene los valores vacios de la columna `Age` con el promedio de los otros valores existentes en dicha columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44.000000\n",
       "1    27.000000\n",
       "2    30.000000\n",
       "3    38.000000\n",
       "4    40.000000\n",
       "5    35.000000\n",
       "6    38.777778\n",
       "7    48.000000\n",
       "8    50.000000\n",
       "9    37.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Age'].fillna(value=dataset['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos lo propio con `Salary` que llene sus valores vacios con el promedio de los otros valores existentes en dicha columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72000.000000\n",
       "1    48000.000000\n",
       "2    54000.000000\n",
       "3    61000.000000\n",
       "4    63777.777778\n",
       "5    58000.000000\n",
       "6    52000.000000\n",
       "7    79000.000000\n",
       "8    83000.000000\n",
       "9    67000.000000\n",
       "Name: Salary, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Salary'].fillna(value=dataset['Salary'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [40.0 63777.77777777778]\n",
      " [35.0 58000.0]\n",
      " [38.77777777777778 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificando Variables categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Porque es necesario codificar las variables categóricas?**\n",
    "\n",
    "Observemos nuestro dataset original y vemos que tenemos dos variables categóricas `Country` y `Purchased`\n",
    "Son variables categoricas porque simplemente ellas contienen categorias:\n",
    "\n",
    "* `Country` tiene tres categorias : France, Spain, Germany\n",
    "* `Purchased` tiene dos categorias: Yes, No.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que los modelos de aprendizaje automático se basan en ecuaciones matemáticas, puedes entender intuitivamente que causaría algún problema si mantenemos los valores de `Country` y `Purchased` como texto.\n",
    "\n",
    "Porque solo queremos numeros en las ecuaciones asi que necesitamos codificar las variables categóricas. Eso es codificar el texto que tenemos como valores de `Country` y `Purchased` en números\n",
    "\n",
    "Entonces, codificamos la variable independiente `Country` con la clase `LabelEncoder` [LabelEncoder](# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder\n",
    " \"sklearn.preprocessing.LabelEncoder\")\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['France' 'Spain' 'Germany' 'Spain' 'Germany' 'France' 'Spain' 'France'\n",
      " 'Germany' 'France']\n"
     ]
    }
   ],
   "source": [
    "# Encoding the Independent Variable\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "print(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un objeto LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "# De la matriz X de variables independientes\n",
    "print(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos la columna 0- `Country` y usamos el metodo `fit_transform()` solo sobre esa primera columna de la matriz `X`, \n",
    "haciendo énfasis en todas sus líneas o registros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 0] = labelencoder_X.fit_transform(X[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si detallamos el resultado de la transformación, vemos que la salida contiene 10 valores de la primera columna Country \n",
    "de nuestra matriz `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 1 2 1 0 2 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(X[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALORES DE COUNTRY CODIFICADOS\n",
      "\n",
      "[[0 44.0 72000.0]\n",
      " [2 27.0 48000.0]\n",
      " [1 30.0 54000.0]\n",
      " [2 38.0 61000.0]\n",
      " [1 40.0 63777.77777777778]\n",
      " [0 35.0 58000.0]\n",
      " [2 38.77777777777778 52000.0]\n",
      " [0 48.0 79000.0]\n",
      " [1 50.0 83000.0]\n",
      " [0 37.0 67000.0]] \n",
      "\n",
      "DATASET ORIGINAL\n",
      "\n",
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "# Aquí se han codificado los valores de la columna Country\n",
    "print(\"VALORES DE COUNTRY CODIFICADOS\" +'\\n')\n",
    "print(X, '\\n')\n",
    "print(\"DATASET ORIGINAL\" +'\\n')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces aqui hemos codificado la columna `Country`. Sin embargo, puede suceder algún problema.\n",
    "El problema es que los modelos de aprendizaje se basan en ecuaciones y es bueno que hayamos \n",
    "reemplazado el texto por números para que podamos incluir los números en las ecuaciones, pero al interpretar números, tenemos la siguiente situación:\n",
    "\n",
    "Dado que uno es 1 es `>` que 0 y 2 es `>` 1 las ecuaciones en el modelo pensaran que `Spain` tiene un valor mas \n",
    "alto que `Alemania` y `France`\n",
    "\n",
    "Y que `Germany` tiene un valor mas alto que `France`, y este no es el caso.\n",
    "**Estas son en realidad tres categorías y no hay un orden relacional entre las tres.** \n",
    "\n",
    "No se puede comparar diciendo que `Spain` es mas grande que `Germany` o que `Germany` es mas grande que `France`, esto no tiene  ningun sentido\n",
    "\n",
    "Si tuviéramos, por ejemplo, el tamaño variable catalogado como pequeño, mediano y grande, entonces sí podríamos expresar órdenes entre los valores de esta variable porque grande es mayor que el mediano y el mediano es mayor que el pequeño "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asi que para prevenir que las ecuaciones del aprendizaje automatico piensen que `Germany` es mas grande que `France` y `Spain` mas grande que `Germany` usaremos una variable que en el mundo de Ciencia de Datos es llamada **dummy variables**\n",
    "\n",
    "Entendamos primero que es una variable Dummy, tomando como referencia esta respuesta https://discuss.analyticsvidhya.com/t/what-is-a-dummy-variable/18960\n",
    "\n",
    "> Una variable dummy es una variable ficticia, artificial y es creada para representar un atributo con dos o mas categorías o niveles distintos\n",
    "\n",
    "Como es el caso de nuestra columna `Country` en la matriz `X`\n",
    "\n",
    "**¿Por qué son utilizadas las variables dummys?**\n",
    "\n",
    "> En el análisis de regresiones, por ejemplo, se tratan todas las variables independientes (X) como numéricas\n",
    "Las variables numéricas son variables de escala de intervalo o relación cuyos valores son directamente comparables.\n",
    "\n",
    "> Por ejemplo: \n",
    "\n",
    "> '10 es el doble de 5 ', o' 3 menos 1 es igual a 2 '. \n",
    "\n",
    "> A menudo, sin embargo, es posible que se desee incluir un atributo o una variable de escala nominal como 'Marca del producto' o 'Tipo de defecto' en su estudio. \n",
    "\n",
    "> Supongamos que se tienen tres tipos de defectos, numerados como '1', '2' y '3'. En este caso, '3 menos 1' no significa nada ... no se puede restar el defecto 1 del defecto 3.\n",
    "\n",
    "> Los números aquí se usan para indicar o identificar los niveles de 'Tipo de defecto' y no tienen un significado intrínseco propio. Las variables ficticias se crean en esta situación para 'engañar' correctamente al algoritmo de regresión analizando atributos de variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, para el contexto de nuestra variable categórica `Country`, como tenemos 3 paises `Spain, Germany, France` es decir tres categorías, esto significa que en lugar de tener una sola columna aquí `Country`, vamos a tener tres columnas, vamos a tener una cantidad de columnas igual a la cantidad de categorías\n",
    "\n",
    "![alt text](https://cldup.com/4IZ1m2ZEH6-3000x3000.png \"Dividing Country on categories values\")\n",
    "\n",
    "\n",
    "Cada columna correspondera a un pais France, Spain, Germany columns \n",
    "Y en cada columna va a haber uno o cero\n",
    "\n",
    "Por ejemplo en la columna `France`, va a existir un 1 si el pais es France y 0 si el pais no es France\n",
    "\n",
    "\n",
    "![alt text](https://cldup.com/gPt-CL4gaV-3000x3000.png \"Dividing Country on categories values\")\n",
    "\n",
    "\n",
    "Entonces, vamos a contrastar la columna Country con cada categorización que se hiz de ella, se usará la clase llamada\n",
    "`OneHotEncoder` - http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder \n",
    "\n",
    "Creamos un objeto OneHotEncoder con el atributo `categorical_features` que especifica que features son tratadas como categoricas, que en este caso el valor sera el arreglo de los elementos de la columna 0, que es `Country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos lo anterior a nuestra matriz `X` usando el metodo `fit_transform()` y solo tenemos que tomar la primera columna de X porque se le especificó antes a índice cero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.40000000e+01,\n",
       "        7.20000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.70000000e+01,\n",
       "        4.80000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.00000000e+01,\n",
       "        5.40000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n",
       "        6.10000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n",
       "        6.37777778e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.50000000e+01,\n",
       "        5.80000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.87777778e+01,\n",
       "        5.20000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n",
       "        7.90000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.00000000e+01,\n",
       "        8.30000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n",
       "        6.70000000e+04]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como resultado miramos este dataset resultante \n",
    "\n",
    "![alt text](https://cldup.com/ucjZuzCUSd-3000x3000.png \"\")\n",
    "\n",
    "Y lo comparamos con nuestro dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la primera columna `Country` (abajo) fue reemplazada por tres columnas (las `0,1,2` de la derecha) y aun tenemos las columnas de `Age` y `Salary`. \n",
    "\n",
    "Recordar que `Purchased` fue descartada porque es una variable dependiente\n",
    "\n",
    "Observando los resultados basados en esta codificacion de la variable categorica `Country` en relacion con las nuevas columnas credas a partir de sus categorias de países ... \n",
    "\n",
    "![alt text](https://cldup.com/iL8I1rOMP3-3000x3000.png \"Comparando resultados dataset original y el transformado categoricament\")\n",
    "\n",
    "Lo primero a identificar es: \n",
    "\n",
    "* La columna 0 es `France`  \n",
    "* La columna 1 es `Germany`  \n",
    "* La columna 2 es `Spain`\n",
    "\n",
    "Sabemos que la primera línea que no tiene fila de salida es el país Francia (columna 0 verde)\n",
    " y dado que la primera observación o muestra es Francia, entonces eso significa que esta primera columna le corresponde a Francia entonces toma un valor de 1\n",
    "\n",
    "La segunda entrada  es Alemania (rojo). , entonces esta va a ser 0 aquí porque la primera observación es Francia y no Alemania\n",
    "\n",
    "Y  lo mismo para el caso de la tercera columna que es España (negro) cuya primera observación es Francia y no España entonces tambien se tiene un valor de 0\n",
    "\n",
    "**Y asi es como se codifican variables dummy asegurándose de que los modelos de aprendizaje automático no atribuyan en orden a las variables categóricas **\n",
    "\n",
    "No tendremos que usar el codificador para `Purchased`, solo necesitaremos utilizar el codificador de etiquetas `LabelEncoder`, ya que como la variable dependiente, el modelo de aprendizaje automático sabrá que \n",
    "es una categoría y que no hay un orden entre los dos.\n",
    "\n",
    "Tomamos el vector de variables dependientes que es solo la ultima columna `Purchased`, es decir la tercera y usamos \n",
    "el `labelencoder` para crear un objeto de tipo `LabelEncoder` para `y`, dado que el anterior ya fue transformado para `X` \n",
    "https://cldup.com/LHn0g0Qu46.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_X.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparemos la columna Purchased del dataset origina, con y categorizada como variable dependiente\n",
    "\n",
    "![alt text](https://cldup.com/LHn0g0Qu46.png \"\")\n",
    "\n",
    "\n",
    "Es asi de esta manera como hemos creado nuestros `LabelEncoder` objects los cuales tienen la función de \n",
    "ajustar o fijar a `X` e `y` y los transformaran a `X` en una matriz independiente y a `y` en un vector de variable dependiente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividiendo el dataset en uno de entrenamiento y uno de pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un dataset de 10 muestras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como en cualquier  modelo de ML lo dividiremos en dos separados conjuntos de datos, de entrenamiento y de pruebas\n",
    "\n",
    "¿Por qué?\n",
    "\n",
    "Bien. Nuestros modelos o algoritmos aprenderán de los datos para hacer predicciones u otros objetivos de aprendizaje \n",
    "automático, por lo que el modelo de aprendizaje automático deberá comprender algunas correlaciones que existen \n",
    "en nuestro conjunto de datos \n",
    "\n",
    "Si usmaos un solo conjunto de datos, estaríamos sobre entrenando al modelo o éste estaría aprendiendo demasiado\n",
    "sobre unos datos en particular o sobre ciertas correlaciones nada mas\n",
    "Aquí no es probable que el rendimiento sea el esperado. Es necesario que el modelo aprenda con diferentes datos\n",
    "y por ende diferentes correlaciones\n",
    "\n",
    "Es como cuando un estudiante aprende de memoria su lección, y entonces, cuando toma el exámen, podrá estar en problemas \n",
    "porque aprendió la lección demasiado de memoria y no logra realizar una conexión entre lo que ha aprendido y el examen \n",
    "Es lo mismo para machine learning\n",
    "\n",
    "Nosotros construimos el modelo de ML sobre un dataset (el de entrenamiento), pero para probarlo será sobre uno nuevo \n",
    "el cual será ligeramente diferente del que construimos (el de pruebas)\n",
    "\n",
    "\n",
    "El conjunto de datos de entrenamiento que es sobre el cual construimos el modelo.\n",
    "El conjunto de datos de prueba es sobre el cual probamos el modelo y el que sea ligeramente diferente \n",
    "o tenga diferentes correlaciones del de entrenamiento, hace que los modelos de ML entiendan bien las correlaciones, \n",
    "y las extrapolen o apliquen a nuevos conjuntos y situaciones nuevas.\n",
    "\n",
    "Esa es la idea de tener datos de prueba y datos de entrenamiento \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "#Importaremos la libreria de cross validation\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos nuestro dataset de pruebas, lo que haremos es crear las variables \n",
    "`X_train`, `X_test` `y_train`, `y_test`\n",
    "\n",
    "Esto hara que exista un dataset de entrenamiento y de pruebas para las variables independientes `X` `Country`, `Age`, `Salary` y un dataset de entrenamiento y de pruebas para el vector de variable dependiente `y` `Purchased`\n",
    "\n",
    "* `X_train` es la parte de entrenamiento de la matriz de caracteristicas de variables independientes\n",
    "* `X_test` es la parte de pruebas de la matriz de caracteristicas de variables independientes\n",
    "\n",
    "* `y_train` es la parte de entrenamiento de las variables dependientes que es asociada a `X_train`\n",
    "\n",
    "Esto significa que tenemos los mismos índices para ámbos con las mismas observaciones o muestras\n",
    "\n",
    "* `y_test`  es la parte de pruebas del vector de la variable dependiente asociado a `X_test`\n",
    "y entonces y definiremos sus valores al mismo tiempo.\n",
    "\n",
    "\n",
    "Utilizamos entonces la función [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html \"sklearn.model_selection.train_test_split\") para generar cada uno de los datasets de pruebas y de entrenamiento tanto para las variables independientes como la independiente.\n",
    "\n",
    "Sus parámetros son:\n",
    "\n",
    "\n",
    "* El primer parámetro debe ser un array, asi que le pasamos la variable `X` categorizada que contiene la primera columna de `X` es decir `Country` que es la matriz `X` de variables independientes.\n",
    "Además incluye los daots de `Age` y `Salary`\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.40000000e+01,\n",
       "        7.20000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 2.70000000e+01,\n",
       "        4.80000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 3.00000000e+01,\n",
       "        5.40000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.80000000e+01,\n",
       "        6.10000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 4.00000000e+01,\n",
       "        6.37777778e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.50000000e+01,\n",
       "        5.80000000e+04],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 3.87777778e+01,\n",
       "        5.20000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.80000000e+01,\n",
       "        7.90000000e+04],\n",
       "       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 5.00000000e+01,\n",
       "        8.30000000e+04],\n",
       "       [1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.70000000e+01,\n",
       "        6.70000000e+04]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El segundo parámetro que le pasamos es `y` que es el vector variable independiente correspondiente a `Purchased` ya codificado como variable categórica también."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `X` e `y` estamos colocando el dataset entero, ambos son arreglos\n",
    "\n",
    "* El próximo parámetro `test_size` corresponde al tamaño del dataset de pruebas que queremos escoger.\n",
    "\n",
    "Así por ejemplo, si colocamos `test_size=0.5` esto significa una división del 50%, lo que genera que \n",
    "la mitad de los datos va al conjunto de prueba y la otra mitad va al conjunto de entrenamiento.\n",
    "\n",
    "Una buena elección para el tamaño de pruebas es generalmente `0.2` es decir el `20%`  o `0.25` \n",
    "o incluso 3%. En algunos casos raros tendremos el `4%` pero casi nunca el `0.5`\n",
    "\n",
    "Escogemos el `2%` lo que significa que tendremos 10 muestras u observaciones. \n",
    "\n",
    "Entonces eso significa que **tendremos dos muestras en el conjunto de prueba y ocho muestras  en el conjunto de entrenamiento.** \n",
    "\n",
    "* El próximo parámetro es `train_size` es decir el tamaño del dataset de entrenamiento, pero como `test_size` mas `train_size` es igual a 1, no es necesario colocarlo, ya que sería redundante\n",
    "\n",
    "* random_state es una semilla o fuente de datos para generación de valores aleatorios para los conjuntos de datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, si miramos, tenemos:\n",
    "\n",
    "- 8 muestras en `X_train` y 2 muestras en `X_test` que corresponden a las variables independientes de\n",
    "`Country` (categorizadas), `Age` y `Salary` \n",
    "\n",
    "Y lo mismo para la salida:\n",
    "\n",
    "- En `y_train` se tienen 8 muestras y 2 muestras en `y_test` que corresponde al vector de variable dependiente `Purchased`\n",
    "\n",
    "Detallemos los 4 datasets de pruebas y entrenamiento\n",
    "\n",
    "![alt text](https://cldup.com/xXiPoQDrJZ-3000x3000.png \"Training and test datasets\")\n",
    "\n",
    "\n",
    "Y entonces, lo que sucede es que estamos construyendo nuestro modelo, estaableciendo algunas \n",
    "correlaciones entre las variables independientes y la variable dependiente aquí.\n",
    "\n",
    "Y una vez que el modelo de ML entienda las correlaciones entre variables independientes\n",
    "y la variable dependiente, nosotros probaremos si el modelo puede aplicar las correlaciones que ha entendido  basándose en el conjunto de entrenamiento y en el conjunto de prueba\n",
    "\n",
    "Esto significa que miraremos si podemos predecir que este registro de indice cero de conjunto de pruebas `X_test` (rojo) no va a comprar el producto en y_test (naranja)\n",
    "\n",
    "![alt text](https://cldup.com/ViVGGFOFrO-3000x3000.png \"Training and test datasets\")\n",
    "\n",
    "\n",
    "Esto es capaz de predecirlo basado en lo que ha aprendido del conjunto de entrenamiento\n",
    "Por lo tanto, cuanto mejor aprenda las correlaciones en el conjunto de entrenamiento, \n",
    "mejor será la predicción de los resultados en el conjunto de prueba.\n",
    "\n",
    "Pero si se aprende demasiado de memoria las correlaciones de los conjuntos \n",
    "de entrenamiento, es decir como cuando uno se aprende de memoria y no entendiéndolos, \n",
    "entonces tendrá problemas para predecir lo que está sucediendo sobre el \n",
    "conjunto de pruebas, Porque se aprende por correlaciones difíciles, si no se\n",
    "entendió muy bien la lógica y no podrá hacer buenas predicciones.\n",
    "\n",
    "\n",
    "Esto es llamado overfitting o sobre entrenamiento\n",
    "\n",
    "Lo realmente importante es entender que necesitamos tener dos diferentes datasets \n",
    "\n",
    "- Training set con el cual el modelo de ML aprende \n",
    "- Test set, sobre el cual probamos si el modelo de ML aprendió correctamente las correlaciones\n",
    "\n",
    "Ahora conocemos como dividir nuestro dataset dentro de un conjunto de entrenamiento y de pruebas.\n",
    "Esto debe hacerse e cualquier modelo ML en donde hay que probar el rendimiento de mi modelo, y se prueba con un conjunto separado de datos de pruebas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling - Escalamiento de características"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Por qué necesitamos tener bajo una misma escala o espacio de dimensión las características o datos?**\n",
    "\n",
    "\n",
    "Tenemos dos columnas: `Age` y `Salary` que contienen valores numéricos:\n",
    "\n",
    "![alt text](https://cldup.com/GLoEjIVD-9-1200x1200.png \"datasets\")\n",
    "\n",
    "Notemos que las variables no están en la misma escala porque ellas van de esta forma:\n",
    "\n",
    "En la columna  `Age`: desde 27 a 50\n",
    "En la columna `Salary`: desde 48k hasta 83k\n",
    "\n",
    "Así que `Salary` and `Age` no tienen la misma escala, lo que cuasará algunos errores en nuestros modelos de ML.\n",
    "\n",
    "**¿Por que esto?**\n",
    "\n",
    "Es porque los modelos de ML se basan en lo que se llama la distancia euclidiana\n",
    "\n",
    "![alt text](https://cldup.com/9_ZUuU8uj3-3000x3000.png \"Distancia Euclidiana\")\n",
    "\n",
    "La distancia Euclidiana entre dos puntos de datos es la raiz cuadrada de la suma de las coordenadas al cuadrado \n",
    "Bien, actualmente con `Age` y `Salary` pasa lo mismo:\n",
    "Tomemos a `Age` como la coordenada `X` y `Salary` como la coordenada `Y`\n",
    "\n",
    "Y en el modelo en donde se ejecutan esas ecuaciones, se calculan algunas distancias euclidianas entre puntos de observación (por ejemplo, entre `Age` y `Salary`) en función de estas dos coordenadas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Además actualmente el salario tiene un muy buen amplio rango de valores porque va desde 0 hasta 100k, entonces la distancia Euclidiana será dominada por `Salary`, porque por ejemplo si tomamos dos muestras  por ejemplo las del indice 3 y 9: \n",
    "\n",
    "![alt text](https://cldup.com/Ilr6Ym57ZA-3000x3000.png \"datasets\")\n",
    "\n",
    "La distancia Euclidiana calculará la diferencia entre este salario de la muestra 3 y el de la muestra 9. Vamos a calcularla:\n",
    "\n",
    "![alt text](https://cldup.com/tnaoxqKDEp-3000x3000.png \"datasets\")\n",
    "\n",
    "Y nos da la diferencia 31.000\n",
    "Si elevamos este valor de 31.000 al cuadrado nos da 961000000\n",
    "\n",
    "![alt text](https://cldup.com/zq853aOPIP-3000x3000.png \"datasets\")\n",
    "\n",
    "\n",
    "Y ahora tomemos las mismas dos observaciones de las edades \n",
    "\n",
    "![alt text](https://cldup.com/_tW6TpWfpL-3000x3000.png \"datasets\")\n",
    "\n",
    "Da una diferencia de 21 y saquemos su valor al cuadrado, que resulta 441\n",
    "\n",
    "![alt text](https://cldup.com/jUbof_kuW3-3000x3000.png \"datasets\")\n",
    "\n",
    "Y asi podemos claramente evidenciar como la diferencia cuadrada de salario (`961000000`) domina a la diferencia cuadrada de Edad (`441`)\n",
    "\n",
    "Y esto es porque estas dos variables no están en la misma escala.\n",
    "Entonces en mi modelo de ML o en sus ecuaciones será como que no existe porque estará dominado por la diferencia cuadrada del salario\n",
    "\n",
    "Asi que esta es la razon por la cual necesitamos colocar las variables en la misma escala\n",
    "\n",
    "Es decir que vamos a transformar estas dos variables y vamos a tener valores en el mismo rango.\n",
    "\n",
    "Para que no tengamos este tipo de problema con un gran número aquí (en la diferencia cuadrada de salary `961000000`) que domina un número más pequeño aquí (en la diferencia cuadrada de edad `441`) para que eventualmente el número más pequeño no exista\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen entonces dos formas de escalar mis datos. \n",
    "\n",
    "![alt text](https://cldup.com/Hdqaoytglb-3000x3000.png \"datasets\")\n",
    "\n",
    "* Estandarización\n",
    "\n",
    "Una forma muy común es la estandarización, la cual significa que para cada muestra y cada caracteristica, se retira el valor medio de todos los valores de la característica y lo divide por la desviación estándar\n",
    "\n",
    "* Normalización\n",
    "\n",
    "Que significa que resta la característica de observación `X` (muestra `X`) por el valor mínimo de todos los valores futuros y la divide por la diferencia entre el máximo de sus valores futuros y el mínimo de sus valores futuros\n",
    "\n",
    "Esta es la técnica de máximos y mínimos que da como resultado tener nuestros datos en una escala o dimensión\n",
    "\n",
    " Lo principal clave aqui es entender que estamos colocando los mismos valores en el mismo rango y en la misma escala, asi que ninguna variable es dominada por la otra \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miraremos como son transformadas las variables cómo van desde valores grandes y muy diferentes a valores pequeños e iguales.\n",
    "\n",
    "¿Debemos ajustar y transformar las variables ficticias con las cuales representamos las categorias de `Country` y `Purchased`?\n",
    "\n",
    "Como podemos ver las variables ficticias dummy nos permiten cambiar su formato\n",
    "\n",
    "![alt text](https://cldup.com/91bZIvPCew-3000x3000.png \"datasets\")\n",
    "\n",
    "Como se puede ver, las variables ficticias toman un valor de 0 a 1.\n",
    "Entonces, ¿necesitamos escalarlas? Parece que ya están en escala, verdad?\n",
    "\n",
    "Existen dos preguntas que podemos analizar aquí:\n",
    "\n",
    "# 1. ¿Necesitamos ajustar y transformar las variables ficticias?\n",
    "\n",
    "Como podemos ver las variables ficticias nos permiten cambiar su formato \n",
    "y estan con valores entre 0 y 1\n",
    "\n",
    "Algunos dicen que no es necesario escalar estas variables ficticias. \n",
    "Otros dicen que si es necesario porque queremos precisión en las predicciones\n",
    "\n",
    "Muchas veces, esta apreciación depende del contexto y también de que tanta interpretación\n",
    "visual deseo mantener en mis modelos con respecto a apreciar sus datasets, esto en el sentido de que\n",
    "si escalamos, esto sera bueno porque todas mis variables estarán en el mismo rango y esto mejora \n",
    "nuestras predicciones.\n",
    "\n",
    "Pero ver los resultados de escalarlas, en el dataset con 0s y 1s nos obligará a retomar el dataset original\n",
    "para interpretar que muestras pertenecen a que país como en este caso.\n",
    "\n",
    "Por ello, cuando normalizamos es bueno tener en cuenta que los datasets originales (ya llenados los datos faltantes)\n",
    "deben estar guardados para futuras referencias.\n",
    "\n",
    "Así que, como queramos, el no escalar las variables ficticias no arruinará nuestro modelo porque de hecho estará en la misma escala  que las escalas futuras.\n",
    "\n",
    "Aquí las variables que tomamos van entre - 1 y 1. Escalaremos esas demasiadas variables\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Creamos un nuevo objeto de la clase StandardScaler()\n",
    "# para escalar las variables independientes X\n",
    "# Pero hasta ahora solo necesitaremos escalar las características de la matriz X\n",
    "sc_X = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora, de manera muy simple, ajustaremos y transformaremos directamente nuestro conjunto de entrenamiento `X_train` \n",
    "Vamos a transformar `X_train`, así que recalcularemos `X_train` porque queremos que sea de escala, y para hacerlo tomaremos nuestro objeto `sc_X` y luego llamaremos al método `fit_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc_X.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante entender que cuando estamos aplicando nuestro objeto `StandardScaler` a nuestro conjunto de entrenamiento, es necesario hacer un ajuste al objeto de los conjuntos de entrenamiento y luego transformarlo y nos daremos cuenta que para el conjunto de pruebas no se realiza el mismo procedimiento porque aqui nosotros solo\n",
    "transformaremos el conjunto de pruebas.\n",
    "\n",
    "APLICAMOS el metodo `transform()` y no `fit_transform()` en el conjunto de pruebas\n",
    "Para el conjunto de entrenamiento debemos ajustarlo y luego transformar el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos el conjunto de pruebas, no necesita ser ajustado\n",
    "# con fit_transform porque ya esta ajustado al conjunto de entrenamiento\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vemos que en el dataset de entrenamiento X_train, todas las variables pertenecen al mismo rango, estan en la misma escala, se puede detallar que todas las variables estan entre -1 y 1\n",
    "\n",
    "![alt text](https://cldup.com/37UgL3OhFj-1200x1200.png \"datasets\")\n",
    "\n",
    "Esto es perfecto, pues mejorara mucho nuestros modelos de ML\n",
    "\n",
    "Incluso, si algunas veces los modelos de ML no son basados en distancias Euclidianas aún asi es muy necesario hacer\n",
    "Feature scaling porque el algoritmo convergerá mucho mas rapido \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miramos `X_test`\n",
    "\n",
    "![alt text](https://cldup.com/09mg_qLs8q-2000x2000.png \"datasets\")\n",
    "\n",
    "\n",
    "También cuenta con una función a escala y debemos entender que las funciones que se escalan aquí `X_test` son las mismas que las que se obtienen en `X_train`, simplemente porque el objeto `Standard Scaler` fue ajustado a `X_train` mediante esta instrucción anterior\n",
    "\n",
    "`X_train = sc_X.fit_transform(X_train)`\n",
    "\n",
    "Esta es la razon por la cual es importante fijar el objeto `X_train` primero, asi que `X_train` y `X_test` son escalas sobre la misma base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ¿Necesirtamos aplicar escalamiento de caracteristicas al vector de la variable dependiente y? En este caso a y_train y a y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asi es como vemos `y_train`\n",
    "\n",
    "![alt text](https://cldup.com/qcNga7_gv0-3000x3000.png \"datasets\")\n",
    "\n",
    "Es una variable categorica porque toma solo dos valors \n",
    "Y ahora la pregunta es ¿necesitamos aplicar funciones de escala aquí?\n",
    "\n",
    "Por esta vez no es necesario, porque este es un problema de clasificación con una categoria llamada variable dependiente\n",
    "\n",
    "Cuando se trabajen regresiones en donde la variable dependiente tomará un gran rango de valores, necesitaremos aplicar la escala de características a la variable dependiente `y` también\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc_y = StandardScaler()\n",
    "# y_train = sc_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos hecho todos los pasos requeridos para el preprocesamiento de datos. \n",
    "los que hay que hacer para preparar cualquier dataset con el cual deseemos construir modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
